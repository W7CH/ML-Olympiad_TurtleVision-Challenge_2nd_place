{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### Imports"
      ],
      "metadata": {
        "id": "fovv5w44_15F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries for data handling, image processing and deep learning\n",
        "import os\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "from glob import glob\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import Subset, DataLoader\n",
        "\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.models import efficientnet_v2_m"
      ],
      "metadata": {
        "id": "Pp4hNcUIZI50"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount Google Drive to directly access dataset files (for Google colab)\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iZ69wCAIb490",
        "outputId": "e2bbc085-560a-4248-d12d-4acf1903b7bc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Paths"
      ],
      "metadata": {
        "id": "UIAjZr3x_6pF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define paths to the training and test datasets as well as where submissions are stored\n",
        "TRAIN_PATH = \"/content/drive/MyDrive/ML Olympiad - TurtleVision Challenge/Data/train\"\n",
        "TEST_PATH = \"/content/drive/MyDrive/ML Olympiad - TurtleVision Challenge/Data/test\"\n",
        "SUBMISSION_PATH = \"/content/drive/MyDrive/ML Olympiad - TurtleVision Challenge/Submissions\""
      ],
      "metadata": {
        "id": "iD5MxUUpb08S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data preprocessing & splitting"
      ],
      "metadata": {
        "id": "KP7YvKwC_9Dg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Move to the folder containing the challenge data\n",
        "os.chdir(\"/content/drive/MyDrive/ML Olympiad - TurtleVision Challenge/Data/\")"
      ],
      "metadata": {
        "id": "nN2E6nRscE-l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply transformations to the training & validation images for augmentation\n",
        "tr_transform = transforms.Compose([\n",
        "    transforms.RandomHorizontalFlip(), # Randomly flip images horizontally to increase dataset diversity\n",
        "    transforms.RandomVerticalFlip(), # Randomly flip images vertically\n",
        "    transforms.RandomRotation(degrees=(10, 60)), # Rotate images within the specified degree range\n",
        "    transforms.ToTensor(), # Convert images to tensor format for PyTorch processing\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]) # Normalize images using standard normalization\n",
        "])\n",
        "\n",
        "# Load training & val data using the defined transformations\n",
        "trainset = torchvision.datasets.ImageFolder(root='train', transform=tr_transform)\n",
        "\n",
        "# Split the training data into training & val sets to evaluate model performance\n",
        "train_size = int(0.8 * len(trainset))\n",
        "val_size = len(trainset) - train_size\n",
        "trainset, valset = torch.utils.data.random_split(trainset, [train_size, val_size])\n",
        "\n",
        "# Create data loaders for both training and val sets to iterate through the dataset in batches (process multiple images in one iteration)\n",
        "trainloader = DataLoader(trainset, batch_size=32, shuffle=True, num_workers=2) # Shuffling helps to prevent the model from learning the order of the examples\n",
        "valloader = DataLoader(valset, batch_size=32, shuffle=False, num_workers=2)"
      ],
      "metadata": {
        "id": "doe2cKNibMYy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Modeling"
      ],
      "metadata": {
        "id": "0OaO2CNAADj8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load a pre-trained EfficientNet V2-M model: https://pytorch.org/vision/main/models/efficientnetv2.html\n",
        "model = efficientnet_v2_m(weights=torchvision.models.EfficientNet_V2_M_Weights.DEFAULT) #DEPRECATED: pretrained=True"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4ucBekdCbU1s",
        "outputId": "904c50ff-dbdb-419a-9ea3-3f8424232d06"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=EfficientNet_V2_M_Weights.IMAGENET1K_V1`. You can also use `weights=EfficientNet_V2_M_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/efficientnet_v2_m-dc08266a.pth\" to /root/.cache/torch/hub/checkpoints/efficientnet_v2_m-dc08266a.pth\n",
            "100%|██████████| 208M/208M [00:02<00:00, 78.4MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Modify the last layer of the classifier with the appropriate number of output classes (6 in our case)\n",
        "num_ftrs = model.classifier[-1].in_features\n",
        "model.classifier[-1] = nn.Linear(num_ftrs, 6)"
      ],
      "metadata": {
        "id": "RyM3N6if9Hb9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the device to GPU if available for faster training, else use CPU\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Define the number of epochs the fine tuning of the pretrained model\n",
        "num_epochs = 100\n",
        "\n",
        "# Define the loss as cross-entropy for multi-class classification\n",
        "criterion = nn.CrossEntropyLoss() # https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html\n",
        "\n",
        "# Set up the optimizer to Adam with an initial learning rate\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.0001) # https://pytorch.org/docs/stable/generated/torch.optim.Adam.html#adam\n",
        "\n",
        "# Define a lr scheduler to reduce it based on validation performance\n",
        "lr_schedulerplateau = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.7, patience=20, verbose=True) # After a patience of 20 steps with no val loss improvement, it reduces the lr by multiplying it by 0.7"
      ],
      "metadata": {
        "id": "_QERagY7baZc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Store loss & accuracy values through the training\n",
        "train_losses, valid_losses = [], []\n",
        "train_accs, valid_accs = [], []\n",
        "valid_loss_min = np.Inf  # track change in validation loss\n",
        "\n",
        "# Move the model to the device (CPU or GPU)\n",
        "model = model.to(device)\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(num_epochs):\n",
        "    running_loss = 0.0\n",
        "    train_loss = 0.0\n",
        "    valid_loss = 0.0\n",
        "    train_running_corrects= 0.0\n",
        "    valid_running_corrects = 0.0\n",
        "\n",
        "    for i, data in enumerate(trainloader, 0):\n",
        "        inputs, labels = data\n",
        "        inputs, labels = inputs.to(device), labels.to(device) # Move data to the appropriate device (CPU or GPU)\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(inputs) # Compute predicted outputs by passing inputs to the model\n",
        "        loss = criterion(outputs, labels) # Calculate the batch loss\n",
        "\n",
        "        # Backward and optimize\n",
        "        optimizer.zero_grad() # Clear gradients from the previous step\n",
        "        loss.backward() # Compute gradient of the loss with respect to model parameters\n",
        "        optimizer.step() # Perform a single optimization step to update parameters\n",
        "\n",
        "        train_loss += loss.item() * inputs.size(0)\n",
        "\n",
        "        # Track the accuracy\n",
        "        _, preds = torch.max(outputs, 1)\n",
        "        train_running_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "    # Set the model to evaluation mode for validation\n",
        "    model.eval()\n",
        "    for i, (images, targets) in enumerate(valloader):\n",
        "        # Move the images and targets to the GPU\n",
        "        images, targets = images.to(device), targets.to(device)\n",
        "\n",
        "        # Perform inference (forward pass) without tracking gradients to save memory and computations\n",
        "        with torch.no_grad():\n",
        "            outputs = model(images)\n",
        "        loss = criterion(outputs, targets) # Calculate the loss between the model's predictions and the true targets\n",
        "\n",
        "        # Update the total validation loss for this batch\n",
        "        valid_loss += loss.item() * images.size(0)\n",
        "\n",
        "        # Adjust the lr based on the validation loss after the batch is processed\n",
        "        lr_schedulerplateau.step(valid_loss)\n",
        "\n",
        "        # Determine the predicted classes by selecting the class with the highest probability\n",
        "        _, preds = torch.max(outputs, 1)\n",
        "\n",
        "        # Calculate the number of correct predictions\n",
        "        valid_running_corrects += torch.sum(preds == targets.data)\n",
        "\n",
        "    # Store training & val losses and accuracies\n",
        "    epoch_loss = train_loss / len(trainloader.dataset)\n",
        "    epoch_acc = train_running_corrects.double() / len(trainloader.dataset)\n",
        "    valid_loss = valid_loss / len(valloader.dataset)\n",
        "    valid_acc = valid_running_corrects.double() / len(valloader.dataset)\n",
        "    train_losses.append(epoch_loss)\n",
        "    valid_losses.append(valid_loss)\n",
        "    train_accs.append(epoch_acc)\n",
        "    valid_accs.append(valid_acc)\n",
        "\n",
        "    print(f\"Epoch [{epoch+1}/{num_epochs}], Train Loss: {epoch_loss:.4f}, Train Acc: {epoch_acc.item()*100:.2f}%, Val Loss: {valid_loss:.4f}, Val Acc: {valid_acc.item()*100:.2f}%\")\n",
        "\n",
        "    # Save the model if the validation loss has decreased\n",
        "    if valid_loss <= valid_loss_min:\n",
        "        print(f\"Validation loss decreased ({valid_loss_min:.6f} --> {valid_loss:.6f}).  Saving model ...\")\n",
        "        torch.save(model.state_dict(), SUBMISSION_PATH + '/model.pth')\n",
        "        valid_loss_min = valid_loss\n",
        "\n",
        "print(\"Training complete.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XQj7ESSbdehk",
        "outputId": "76b2127f-b8b0-4e11-af46-3c766feb599e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/100], Train Loss: 0.0000, Train Acc: 100.00%, Val Loss: 0.0518, Val Acc: 98.89%\n",
            "Validation loss decreased (inf --> 0.051800).  Saving model ...\n",
            "Epoch [2/100], Train Loss: 0.0000, Train Acc: 100.00%, Val Loss: 0.0539, Val Acc: 98.89%\n",
            "Epoch [3/100], Train Loss: 0.0000, Train Acc: 100.00%, Val Loss: 0.0232, Val Acc: 99.44%\n",
            "Validation loss decreased (0.051800 --> 0.023169).  Saving model ...\n",
            "Epoch [4/100], Train Loss: 0.0000, Train Acc: 100.00%, Val Loss: 0.0662, Val Acc: 98.89%\n",
            "Epoch [5/100], Train Loss: 0.0001, Train Acc: 100.00%, Val Loss: 0.0154, Val Acc: 99.44%\n",
            "Validation loss decreased (0.023169 --> 0.015414).  Saving model ...\n",
            "Epoch [6/100], Train Loss: 0.0000, Train Acc: 100.00%, Val Loss: 0.0344, Val Acc: 98.89%\n",
            "Epoch [7/100], Train Loss: 0.0000, Train Acc: 100.00%, Val Loss: 0.0567, Val Acc: 99.44%\n",
            "Epoch [8/100], Train Loss: 0.0000, Train Acc: 100.00%, Val Loss: 0.0236, Val Acc: 98.89%\n",
            "Epoch [9/100], Train Loss: 0.0000, Train Acc: 100.00%, Val Loss: 0.0041, Val Acc: 100.00%\n",
            "Validation loss decreased (0.015414 --> 0.004095).  Saving model ...\n",
            "Epoch [10/100], Train Loss: 0.0000, Train Acc: 100.00%, Val Loss: 0.0330, Val Acc: 98.89%\n",
            "Epoch [11/100], Train Loss: 0.0000, Train Acc: 100.00%, Val Loss: 0.0715, Val Acc: 98.89%\n",
            "Epoch [12/100], Train Loss: 0.0000, Train Acc: 100.00%, Val Loss: 0.0409, Val Acc: 99.44%\n",
            "Epoch [13/100], Train Loss: 0.0000, Train Acc: 100.00%, Val Loss: 0.0180, Val Acc: 99.44%\n",
            "Epoch [14/100], Train Loss: 0.0000, Train Acc: 100.00%, Val Loss: 0.0631, Val Acc: 98.89%\n",
            "Epoch [15/100], Train Loss: 0.0000, Train Acc: 100.00%, Val Loss: 0.0514, Val Acc: 98.89%\n",
            "Epoch [16/100], Train Loss: 0.0000, Train Acc: 100.00%, Val Loss: 0.0371, Val Acc: 99.44%\n",
            "Epoch [17/100], Train Loss: 0.0001, Train Acc: 100.00%, Val Loss: 0.0142, Val Acc: 99.44%\n",
            "Epoch [18/100], Train Loss: 0.0000, Train Acc: 100.00%, Val Loss: 0.0546, Val Acc: 99.44%\n",
            "Epoch [19/100], Train Loss: 0.0000, Train Acc: 100.00%, Val Loss: 0.0753, Val Acc: 98.89%\n",
            "Epoch [20/100], Train Loss: 0.0000, Train Acc: 100.00%, Val Loss: 0.0612, Val Acc: 99.44%\n",
            "Epoch [21/100], Train Loss: 0.0000, Train Acc: 100.00%, Val Loss: 0.0550, Val Acc: 98.89%\n",
            "Epoch [22/100], Train Loss: 0.0000, Train Acc: 100.00%, Val Loss: 0.0436, Val Acc: 98.89%\n",
            "Epoch [23/100], Train Loss: 0.0000, Train Acc: 100.00%, Val Loss: 0.0666, Val Acc: 98.89%\n",
            "Epoch [24/100], Train Loss: 0.0000, Train Acc: 100.00%, Val Loss: 0.0076, Val Acc: 99.44%\n",
            "Epoch [25/100], Train Loss: 0.0000, Train Acc: 100.00%, Val Loss: 0.0587, Val Acc: 99.44%\n",
            "Epoch [26/100], Train Loss: 0.0000, Train Acc: 100.00%, Val Loss: 0.0169, Val Acc: 99.44%\n",
            "Epoch [27/100], Train Loss: 0.0000, Train Acc: 100.00%, Val Loss: 0.0416, Val Acc: 99.44%\n",
            "Epoch [28/100], Train Loss: 0.0001, Train Acc: 100.00%, Val Loss: 0.0264, Val Acc: 99.44%\n",
            "Epoch [29/100], Train Loss: 0.0000, Train Acc: 100.00%, Val Loss: 0.0527, Val Acc: 99.44%\n",
            "Epoch [30/100], Train Loss: 0.0000, Train Acc: 100.00%, Val Loss: 0.0347, Val Acc: 99.44%\n",
            "Epoch [31/100], Train Loss: 0.0000, Train Acc: 100.00%, Val Loss: 0.0152, Val Acc: 99.44%\n",
            "Epoch [32/100], Train Loss: 0.0000, Train Acc: 100.00%, Val Loss: 0.0018, Val Acc: 100.00%\n",
            "Validation loss decreased (0.004095 --> 0.001756).  Saving model ...\n",
            "Epoch [33/100], Train Loss: 0.0000, Train Acc: 100.00%, Val Loss: 0.0506, Val Acc: 99.44%\n",
            "Epoch [34/100], Train Loss: 0.0000, Train Acc: 100.00%, Val Loss: 0.0631, Val Acc: 98.89%\n",
            "Epoch [35/100], Train Loss: 0.0000, Train Acc: 100.00%, Val Loss: 0.0650, Val Acc: 99.44%\n",
            "Epoch [36/100], Train Loss: 0.0000, Train Acc: 100.00%, Val Loss: 0.0625, Val Acc: 98.33%\n",
            "Epoch [37/100], Train Loss: 0.0000, Train Acc: 100.00%, Val Loss: 0.0290, Val Acc: 99.44%\n",
            "Epoch [38/100], Train Loss: 0.0000, Train Acc: 100.00%, Val Loss: 0.0039, Val Acc: 100.00%\n",
            "Epoch [39/100], Train Loss: 0.0000, Train Acc: 100.00%, Val Loss: 0.0308, Val Acc: 99.44%\n",
            "Epoch [40/100], Train Loss: 0.0000, Train Acc: 100.00%, Val Loss: 0.0387, Val Acc: 99.44%\n",
            "Epoch [41/100], Train Loss: 0.0000, Train Acc: 100.00%, Val Loss: 0.0194, Val Acc: 98.89%\n",
            "Epoch [42/100], Train Loss: 0.0000, Train Acc: 100.00%, Val Loss: 0.0459, Val Acc: 99.44%\n",
            "Epoch [43/100], Train Loss: 0.0000, Train Acc: 100.00%, Val Loss: 0.0095, Val Acc: 99.44%\n",
            "Epoch [44/100], Train Loss: 0.0000, Train Acc: 100.00%, Val Loss: 0.0401, Val Acc: 98.89%\n",
            "Epoch [45/100], Train Loss: 0.0000, Train Acc: 100.00%, Val Loss: 0.0635, Val Acc: 99.44%\n",
            "Epoch [46/100], Train Loss: 0.0000, Train Acc: 100.00%, Val Loss: 0.0529, Val Acc: 98.89%\n",
            "Epoch [47/100], Train Loss: 0.0000, Train Acc: 100.00%, Val Loss: 0.0581, Val Acc: 98.89%\n",
            "Epoch [48/100], Train Loss: 0.0000, Train Acc: 100.00%, Val Loss: 0.0319, Val Acc: 99.44%\n",
            "Epoch [49/100], Train Loss: 0.0000, Train Acc: 100.00%, Val Loss: 0.0344, Val Acc: 99.44%\n",
            "Epoch [50/100], Train Loss: 0.0000, Train Acc: 100.00%, Val Loss: 0.0672, Val Acc: 99.44%\n",
            "Epoch [51/100], Train Loss: 0.0000, Train Acc: 100.00%, Val Loss: 0.0466, Val Acc: 99.44%\n",
            "Epoch [52/100], Train Loss: 0.0000, Train Acc: 100.00%, Val Loss: 0.0109, Val Acc: 99.44%\n",
            "Epoch [53/100], Train Loss: 0.0000, Train Acc: 100.00%, Val Loss: 0.0479, Val Acc: 99.44%\n",
            "Epoch [54/100], Train Loss: 0.0000, Train Acc: 100.00%, Val Loss: 0.0442, Val Acc: 99.44%\n",
            "Epoch [55/100], Train Loss: 0.0000, Train Acc: 100.00%, Val Loss: 0.0546, Val Acc: 98.89%\n",
            "Epoch [56/100], Train Loss: 0.0000, Train Acc: 100.00%, Val Loss: 0.0572, Val Acc: 99.44%\n",
            "Epoch [57/100], Train Loss: 0.0000, Train Acc: 100.00%, Val Loss: 0.0570, Val Acc: 99.44%\n",
            "Epoch [58/100], Train Loss: 0.0000, Train Acc: 100.00%, Val Loss: 0.0450, Val Acc: 99.44%\n",
            "Epoch [59/100], Train Loss: 0.0000, Train Acc: 100.00%, Val Loss: 0.0419, Val Acc: 99.44%\n",
            "Epoch [60/100], Train Loss: 0.0000, Train Acc: 100.00%, Val Loss: 0.0497, Val Acc: 99.44%\n",
            "Epoch [61/100], Train Loss: 0.0000, Train Acc: 100.00%, Val Loss: 0.0686, Val Acc: 98.89%\n",
            "Epoch [62/100], Train Loss: 0.0000, Train Acc: 100.00%, Val Loss: 0.0083, Val Acc: 99.44%\n",
            "Epoch [63/100], Train Loss: 0.0000, Train Acc: 100.00%, Val Loss: 0.0101, Val Acc: 99.44%\n",
            "Epoch [64/100], Train Loss: 0.0000, Train Acc: 100.00%, Val Loss: 0.0523, Val Acc: 99.44%\n",
            "Epoch [65/100], Train Loss: 0.0000, Train Acc: 100.00%, Val Loss: 0.0580, Val Acc: 99.44%\n",
            "Epoch [66/100], Train Loss: 0.0000, Train Acc: 100.00%, Val Loss: 0.0179, Val Acc: 98.89%\n",
            "Epoch [67/100], Train Loss: 0.0000, Train Acc: 100.00%, Val Loss: 0.0125, Val Acc: 99.44%\n",
            "Epoch [68/100], Train Loss: 0.0000, Train Acc: 100.00%, Val Loss: 0.0565, Val Acc: 98.89%\n",
            "Epoch [69/100], Train Loss: 0.0000, Train Acc: 100.00%, Val Loss: 0.0482, Val Acc: 98.89%\n",
            "Epoch [70/100], Train Loss: 0.0000, Train Acc: 100.00%, Val Loss: 0.0575, Val Acc: 99.44%\n",
            "Epoch [71/100], Train Loss: 0.0000, Train Acc: 100.00%, Val Loss: 0.0422, Val Acc: 99.44%\n",
            "Epoch [72/100], Train Loss: 0.0000, Train Acc: 100.00%, Val Loss: 0.0464, Val Acc: 99.44%\n",
            "Epoch [73/100], Train Loss: 0.0000, Train Acc: 100.00%, Val Loss: 0.0757, Val Acc: 98.89%\n",
            "Epoch [74/100], Train Loss: 0.0000, Train Acc: 100.00%, Val Loss: 0.0278, Val Acc: 98.89%\n",
            "Epoch [75/100], Train Loss: 0.0000, Train Acc: 100.00%, Val Loss: 0.0073, Val Acc: 99.44%\n",
            "Epoch [76/100], Train Loss: 0.0000, Train Acc: 100.00%, Val Loss: 0.0021, Val Acc: 100.00%\n",
            "Epoch [77/100], Train Loss: 0.0000, Train Acc: 100.00%, Val Loss: 0.0479, Val Acc: 99.44%\n",
            "Epoch [78/100], Train Loss: 0.0000, Train Acc: 100.00%, Val Loss: 0.0561, Val Acc: 99.44%\n",
            "Epoch [79/100], Train Loss: 0.0001, Train Acc: 100.00%, Val Loss: 0.0802, Val Acc: 98.89%\n",
            "Epoch [80/100], Train Loss: 0.0000, Train Acc: 100.00%, Val Loss: 0.0495, Val Acc: 99.44%\n",
            "Epoch [81/100], Train Loss: 0.0000, Train Acc: 100.00%, Val Loss: 0.0359, Val Acc: 99.44%\n",
            "Epoch [82/100], Train Loss: 0.0000, Train Acc: 100.00%, Val Loss: 0.0248, Val Acc: 99.44%\n",
            "Epoch [83/100], Train Loss: 0.0000, Train Acc: 100.00%, Val Loss: 0.0395, Val Acc: 99.44%\n",
            "Epoch [84/100], Train Loss: 0.0000, Train Acc: 100.00%, Val Loss: 0.0429, Val Acc: 99.44%\n",
            "Epoch [85/100], Train Loss: 0.0000, Train Acc: 100.00%, Val Loss: 0.0343, Val Acc: 99.44%\n",
            "Epoch [86/100], Train Loss: 0.0000, Train Acc: 100.00%, Val Loss: 0.0573, Val Acc: 99.44%\n",
            "Epoch [87/100], Train Loss: 0.0000, Train Acc: 100.00%, Val Loss: 0.0874, Val Acc: 98.33%\n",
            "Epoch [88/100], Train Loss: 0.0000, Train Acc: 100.00%, Val Loss: 0.0698, Val Acc: 98.89%\n",
            "Epoch [89/100], Train Loss: 0.0000, Train Acc: 100.00%, Val Loss: 0.0189, Val Acc: 98.89%\n",
            "Epoch [90/100], Train Loss: 0.0000, Train Acc: 100.00%, Val Loss: 0.0458, Val Acc: 98.89%\n",
            "Epoch [91/100], Train Loss: 0.0000, Train Acc: 100.00%, Val Loss: 0.0536, Val Acc: 99.44%\n",
            "Epoch [92/100], Train Loss: 0.0000, Train Acc: 100.00%, Val Loss: 0.0528, Val Acc: 98.89%\n",
            "Epoch [93/100], Train Loss: 0.0000, Train Acc: 100.00%, Val Loss: 0.0603, Val Acc: 98.89%\n",
            "Epoch [94/100], Train Loss: 0.0001, Train Acc: 100.00%, Val Loss: 0.0693, Val Acc: 98.89%\n",
            "Epoch [95/100], Train Loss: 0.0000, Train Acc: 100.00%, Val Loss: 0.0237, Val Acc: 99.44%\n",
            "Epoch [96/100], Train Loss: 0.0000, Train Acc: 100.00%, Val Loss: 0.0529, Val Acc: 99.44%\n",
            "Epoch [97/100], Train Loss: 0.0000, Train Acc: 100.00%, Val Loss: 0.0374, Val Acc: 98.89%\n",
            "Epoch [98/100], Train Loss: 0.0000, Train Acc: 100.00%, Val Loss: 0.0295, Val Acc: 99.44%\n",
            "Epoch [99/100], Train Loss: 0.0000, Train Acc: 100.00%, Val Loss: 0.0678, Val Acc: 98.89%\n",
            "Epoch [100/100], Train Loss: 0.0002, Train Acc: 100.00%, Val Loss: 0.0532, Val Acc: 98.89%\n",
            "Training complete.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Prediction"
      ],
      "metadata": {
        "id": "wwJFbnWpAd_I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a custom dataset class to load the test data containing images of all classes\n",
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, image_paths, transform=None):\n",
        "        self.image_paths = image_paths\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_paths)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        image_path = self.image_paths[index]\n",
        "        image = Image.open(image_path).convert('RGB')\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        return image"
      ],
      "metadata": {
        "id": "W-6DNYzEkYtk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define transform for test data\n",
        "test_transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# Load test images from their directory\n",
        "test_images = glob('test/*.jpg')\n",
        "test_dataset = CustomDataset(test_images, transform=test_transform)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
      ],
      "metadata": {
        "id": "z049PQcWkfsc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model on the test set\n",
        "predictions = []\n",
        "model.eval()  # Set the model to evaluation mode\n",
        "with torch.no_grad():  # Disable gradient tracking since we're only evaluating\n",
        "    for images in test_loader:\n",
        "        # Forward pass to get predictions\n",
        "        images = images.to(device)\n",
        "        outputs = model(images)\n",
        "        _, predicted_classes = torch.max(outputs, 1)\n",
        "        predictions.extend(predicted_classes.tolist())"
      ],
      "metadata": {
        "id": "qQXVX8WfkOli"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get class names from the dataset\n",
        "class_names = [\"barrel_jellyfish\", \"compass_jellyfish\", \"lions_mane_jellyfish\", \"mauve_stinger_jellyfish\", \"moon_jellyfish\", \"plastic_pollution\"]\n",
        "\n",
        "# Map predicted class indices to class names\n",
        "predicted_class_names = [class_names[class_index] for class_index in predictions]"
      ],
      "metadata": {
        "id": "Mz5VNnlCn4Id"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Pair filenames with predicted_class_names\n",
        "filenames = [img.split('/')[-1].replace('.jpg', '') for img in test_images]\n",
        "pairs = list(zip(filenames, predicted_class_names))\n",
        "\n",
        "# Sort pairs based on filenames elements\n",
        "sorted_pairs = sorted(pairs, key=lambda x: x[0])\n",
        "\n",
        "# Unpack sorted pairs into separate lists\n",
        "sorted_filenames, sorted_predicted_class_names = zip(*sorted_pairs)"
      ],
      "metadata": {
        "id": "myh4ZYXfD03Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Submission"
      ],
      "metadata": {
        "id": "x9FAzDpPnOXG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Save predictions to a CSV file for submission\n",
        "results = {'ImageID': sorted_filenames, 'PredictedClass': sorted_predicted_class_names}"
      ],
      "metadata": {
        "id": "QqlbNR8Nkool"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the results for submission\n",
        "results_df = pd.DataFrame(results)\n",
        "results_df.to_csv(SUBMISSION_PATH + '/effv2m_100ep_lrsch.csv', index=False)"
      ],
      "metadata": {
        "id": "hzFwObTalDJ8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Thank you for your attention!"
      ],
      "metadata": {
        "id": "id3nArnOntWl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I look forward to any questions you might have about this notebook. Please feel free to contact me on: https://www.linkedin.com/in/wassim-chakroun/"
      ],
      "metadata": {
        "id": "3xKrtBHdngrB"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "5hol_AoSZCJd",
        "u3_gjqYmIAHy"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
